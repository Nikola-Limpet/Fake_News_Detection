# config.yaml
# Configuration file for Fake News Detection System

# Project Information
project:
  name: "Fake News Detection System"
  version: "1.0.0"
  description: "AI-powered system for detecting misinformation"
  authors:
    - "Lim Petnikola"
    - "Rim Sovichey"
    - "Pha Lyheng"
    - "Sokhonn Raksmeidaravid"

# Data Configuration
data:
  # Data sources
  sources:
    kaggle_dataset: "clmentbisaillon/fake-and-real-news-dataset"
    newsapi_endpoint: "https://newsapi.org/v2"
  
  # Data paths
  paths:
    raw_data: "data/raw/"
    processed_data: "data/processed/"
    train_data: "data/train.csv"
    validation_data: "data/validation.csv"
    test_data: "data/test.csv"
  
  # Data split ratios
  split:
    train: 0.7
    validation: 0.15
    test: 0.15
    random_state: 42
    stratify: true

# Preprocessing Configuration
preprocessing:
  # Text cleaning
  text_cleaning:
    lowercase: true
    remove_urls: true
    remove_html: true
    remove_punctuation: true
    remove_numbers: true
    remove_extra_spaces: true
  
  # NLP processing
  nlp:
    language: "english"
    remove_stopwords: true
    lemmatization: true
    stemming: false
    min_word_length: 2
    max_word_length: 50
  
  # Text limits
  limits:
    min_text_length: 50
    max_text_length: 10000

# Feature Extraction Configuration
features:
  # TF-IDF settings
  tfidf:
    max_features: 5000
    ngram_range: [1, 2]
    min_df: 2
    max_df: 0.95
    use_idf: true
    smooth_idf: true
    sublinear_tf: true
  
  # Word2Vec settings
  word2vec:
    vector_size: 100
    window: 5
    min_count: 2
    workers: 4
    sg: 0  # 0 for CBOW, 1 for Skip-gram
    epochs: 10
  
  # BERT settings
  bert:
    model_name: "bert-base-uncased"
    max_length: 128
    batch_size: 32
    use_gpu: true

# Model Configuration
models:
  # Naive Bayes
  naive_bayes:
    alpha: 1.0
    fit_prior: true
    class_prior: null
  
  # Random Forest
  random_forest:
    n_estimators: 200
    max_depth: 20
    min_samples_split: 5
    min_samples_leaf: 2
    max_features: "sqrt"
    bootstrap: true
    n_jobs: -1
    random_state: 42
  
  # LSTM
  lstm:
    # Architecture
    embedding_dim: 100
    lstm_units: 128
    dropout_rate: 0.5
    recurrent_dropout: 0.5
    bidirectional: true
    
    # Training
    max_length: 100
    vocab_size: 5000
    batch_size: 32
    epochs: 10
    learning_rate: 0.001
    optimizer: "adam"
    loss: "binary_crossentropy"
    metrics: ["accuracy"]
    
    # Callbacks
    early_stopping:
      monitor: "val_loss"
      patience: 3
      restore_best_weights: true
    
    reduce_lr:
      monitor: "val_loss"
      factor: 0.5
      patience: 2
      min_lr: 0.00001
  
  # BERT
  bert:
    # Architecture
    hidden_size: 768
    num_attention_heads: 12
    num_hidden_layers: 12
    
    # Fine-tuning
    dense_units: [256, 128, 64]
    dropout_rate: 0.3
    
    # Training
    batch_size: 16
    epochs: 5
    learning_rate: 2e-5
    warmup_steps: 500
    weight_decay: 0.01
    
  # Ensemble
  ensemble:
    voting: "soft"  # "hard" or "soft"
    weights: [0.2, 0.3, 0.25, 0.25]  # NB, RF, LSTM, BERT
    
# Training Configuration
training:
  # General settings
  seed: 42
  verbose: 1
  
  # Cross-validation
  cross_validation:
    enabled: true
    n_splits: 5
    shuffle: true
    
  # Hyperparameter tuning
  hyperparameter_tuning:
    enabled: true
    method: "grid"  # "grid" or "random"
    scoring: "f1"
    cv: 5
    n_jobs: -1
    
  # Class imbalance handling
  class_balance:
    strategy: "none"  # "none", "oversample", "undersample", "smote"
    sampling_ratio: 1.0
    
  # GPU settings
  gpu:
    use_gpu: true
    gpu_id: 0
    memory_growth: true
    mixed_precision: false

# Evaluation Configuration
evaluation:
  # Metrics to calculate
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc_roc"
    - "confusion_matrix"
    - "classification_report"
    - "matthews_corrcoef"
  
  # Visualization
  visualization:
    plot_confusion_matrix: true
    plot_roc_curve: true
    plot_learning_curves: true
    plot_feature_importance: true
    save_plots: true
    plot_format: "png"
    dpi: 300
  
  # Thresholds
  thresholds:
    confidence_threshold: 0.7
    high_confidence: 0.9
    low_confidence: 0.5

# Explainability Configuration
explainability:
  # LIME settings
  lime:
    enabled: true
    num_features: 10
    num_samples: 5000
    
  # SHAP settings
  shap:
    enabled: true
    max_display: 20
    plot_type: "bar"

# API Configuration
api:
  # Server settings
  host: "0.0.0.0"
  port: 8000
  reload: true
  workers: 4
  
  # Security
  cors:
    enabled: true
    origins: ["*"]
    credentials: true
    
  # Rate limiting
  rate_limit:
    enabled: true
    requests_per_minute: 60
    
  # Caching
  cache:
    enabled: true
    ttl: 3600  # seconds
    max_size: 1000
    
  # Authentication
  auth:
    enabled: false
    api_key_header: "X-API-Key"

# Streamlit Configuration
streamlit:
  # App settings
  page_title: "Fake News Detection System"
  page_icon: "ðŸ“°"
  layout: "wide"
  initial_sidebar_state: "expanded"
  
  # Theme
  theme:
    primary_color: "#3498db"
    background_color: "#f0f2f6"
    secondary_background_color: "#ffffff"
    text_color: "#262730"
    
  # Features
  features:
    show_analytics: true
    show_explanations: true
    enable_batch_upload: true
    max_upload_size: 10  # MB

# Logging Configuration
logging:
  # Log levels
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  
  # Log files
  paths:
    app_log: "logs/app.log"
    training_log: "logs/training.log"
    prediction_log: "logs/predictions.log"
    error_log: "logs/errors.log"
  
  # Rotation
  rotation:
    max_bytes: 10485760  # 10MB
    backup_count: 5
  
  # Format
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# External Services
external_services:
  # NewsAPI
  newsapi:
    enabled: true
    api_key: "${NEWS_API_KEY}"  # From environment variable
    endpoints:
      top_headlines: "/v2/top-headlines"
      everything: "/v2/everything"
    
  # Kaggle
  kaggle:
    enabled: true
    username: "${KAGGLE_USERNAME}"
    key: "${KAGGLE_KEY}"
    
  # MongoDB (optional)
  mongodb:
    enabled: false
    uri: "mongodb://localhost:27017/"
    database: "fake_news_detection"
    collections:
      predictions: "predictions"
      models: "models"
      feedback: "feedback"
  
  # Redis (optional)
  redis:
    enabled: false
    host: "localhost"
    port: 6379
    db: 0
    password: null

# Deployment Configuration
deployment:
  # Environment
  environment: "development"  # development, staging, production
  
  # Docker
  docker:
    image_name: "fake-news-detection"
    tag: "latest"
    registry: "docker.io"
    
  # Cloud platforms
  cloud:
    provider: "aws"  # aws, gcp, azure
    region: "us-east-1"
    
  # Model serving
  serving:
    platform: "fastapi"  # fastapi, flask, tensorflow-serving
    model_format: "pickle"  # pickle, h5, savedmodel, onnx
    
  # Monitoring
  monitoring:
    prometheus:
      enabled: true
      port: 9090
    grafana:
      enabled: true
      port: 3000

# Performance Optimization
optimization:
  # Model compression
  compression:
    quantization: false
    pruning: false
    knowledge_distillation: false
    
  # Inference optimization
  inference:
    batch_predictions: true
    async_processing: true
    use_onnx: false
    use_tflite: false
    
  # Resource limits
  resources:
    max_memory: "4GB"
    max_cpu_percent: 80
    timeout_seconds: 30

# Paths Configuration
paths:
  # Model paths
  models:
    base: "models/"
    naive_bayes: "models/naive_bayes_model.pkl"
    random_forest: "models/random_forest_model.pkl"
    lstm: "models/best_lstm_model.h5"
    bert: "models/best_bert_lstm_model.h5"
    ensemble: "models/ensemble_model.pkl"
  
  # Feature extractor paths
  features:
    tfidf: "models/tfidf_vectorizer.pkl"
    word2vec: "models/word2vec_model.pkl"
    tokenizer: "models/lstm_tokenizer.pkl"
    preprocessor: "models/preprocessor.pkl"
  
  # Output paths
  outputs:
    reports: "outputs/reports/"
    visualizations: "outputs/plots/"
    predictions: "outputs/predictions/"
    exports: "outputs/exports/"

# Experiment Tracking
mlflow:
  enabled: false
  tracking_uri: "http://localhost:5000"
  experiment_name: "fake_news_detection"
  artifact_location: "mlruns/"
  
# Testing Configuration
testing:
  # Test data
  test_size: 0.2
  
  # Test types
  unit_tests: true
  integration_tests: true
  performance_tests: true
  
  # Coverage
  min_coverage: 80
  
  # Benchmarks
  benchmarks:
    min_accuracy: 0.85
    min_f1_score: 0.83
    max_inference_time: 1.0  # seconds

# Notification Settings
notifications:
  # Email notifications
  email:
    enabled: false
    smtp_server: "smtp.gmail.com"
    smtp_port: 587
    sender: "noreply@example.com"
    recipients: ["admin@example.com"]
    
  # Slack notifications
  slack:
    enabled: false
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#fake-news-detection"

# Version Control
version_control:
  models:
    versioning_enabled: true
    naming_convention: "model_v{version}_{timestamp}"
    keep_last_n_versions: 5
    
  data:
    track_changes: true
    backup_enabled: true
    backup_frequency: "daily"